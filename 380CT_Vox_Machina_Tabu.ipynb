{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabu Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second meta-heuristic algorithm that will be implemented to the TSP is 'Tabu Search'. This algorithm consists of using an iterative solution implementation of a set of problem solutions and moving from one solution to another in the same neighbourhood of each related solution. This means maintaining a short term memory of specific changes of recent moves within the search space and preventing future moves from undoing those changes (Panigrahi, 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabu Search moves towards a solution $s*$ that attempts to minimise $f$, a cost function. A class of simple modifications is defined that is able to be applied to a solution ready to advance to the next one. The solution $s'$ is obtained by modifying $m$ to solution $s$. The set of the acceptable modifications we call $M$ which is displayed as \n",
    "\n",
    "$$s' = s \\oplus m, m \\in M$$\n",
    "\n",
    "this actuates the neighbourhood definition $N(s)$ of every solution $s$.\n",
    "\n",
    "The main feature of Tabu Search is to forbid any moves that could bring the process back to one of the previously visited solutions. The final moves can be collected in a list $T$ of all forbidden moves. For a fixed number of iterations, a move will remain forbidden and the oldest element will be deleted on each iteration. The final modification will be added to the head of the queue.\n",
    "\n",
    "The tabu status is assigned to different constituents $t_i$ of moves. Every constituent of the forbidden moves is collected in a separate list such as $T_i$ and tabu conditions of the form\n",
    "\n",
    "$$t_i(m)\\in T_i (i = 1, ... ,t)$$\n",
    "\n",
    "are introduced. Move $m$ will then be forbidden if it satisfies all tabu conditions.\n",
    "\n",
    "\n",
    "(C.-N. Fiechter, 1992)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, time, random, sys\n",
    "from random import randint, shuffle\n",
    "import networkx as graphs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class CompleteWGraph:\n",
    "    n = 0\n",
    "    p = 0\n",
    "    lower_weight = 0\n",
    "    upper_weight = 0\n",
    "    distmatrix = {}\n",
    "    w_edges = []\n",
    "    def __init__(self,n,p,lower_weight,upper_weight):\n",
    "        \"\"\"n: number of nodes\n",
    "        p: prob of 2 nodes being connected (between 0-1)\n",
    "        lower/upper weight: range of possible weight values\"\"\"\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.lower_weight= lower_weight\n",
    "        self.upper_weight = upper_weight\n",
    "    def random_weighted_graph(self):\n",
    "        g = graphs.gnp_random_graph(self.n,self.p)\n",
    "        m = g.number_of_edges()\n",
    "        weights = [random.randint(self.lower_weight, self.upper_weight) for r in range(m)]\n",
    "        #unweighted connections\n",
    "        uw_edges = g.edges()\n",
    "        # Create weighted graph edge list\n",
    "        i=0\n",
    "        w_edges = []\n",
    "        ret_graph = graphs.Graph()\n",
    "        for edge in uw_edges:\n",
    "        #w_edges = [uw_edges[i][0], uw_edges[i][1], weights[i]]\n",
    "        #w_edges+={(edge[0],edge[1]):weights[i]}\n",
    "            ret_graph.add_edge(edge[0],edge[1],weight=weights[i])\n",
    "            i =i +1\n",
    "        #print(w_edges)\n",
    "        #return graphs.Graph(w_edges, weighted = True,s=weights)\n",
    "        return ret_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g1_data = CompleteWGraph(10,0.6,5,20)\n",
    "#g1 = g1_data.random_weighted_graph()\n",
    "\n",
    "#weightdict = g1.get_edge_data(0,2)\n",
    "#print(weightdict)\n",
    "#print(g1.get_edge_data(0,2)['weight'])\n",
    "\n",
    "#g1_data.createDistanceMatrix(g1)\n",
    "#print(\"g1 distance matrix\")\n",
    "#print(g1_data.distmatrix)\n",
    "\n",
    "###  Data Format is dict:\n",
    "#           data[node_name] = gives you a list of link info\n",
    "#           data[link_index][0] = name of node that edge goes to\n",
    "#           data[link_index][1] = weight of that edge\n",
    "def cook_data(nodes, probability, min_weight, max_weight):\n",
    "    linkset = []\n",
    "    links = {}\n",
    "\n",
    "    if min_weight>max_weight:\n",
    "        print('Lower weight cannot be greater then upper weight for the weight range. ')\n",
    "        sys.exit()\n",
    "    if probability<0 or probability>1:\n",
    "        print('Probability incorrect. Must be between 0 and 1. ')\n",
    "        sys.exit()\n",
    "    g1_data = CompleteWGraph(nodes, probability, min_weight, max_weight)\n",
    "    g1 = g1_data.random_weighted_graph()\n",
    "    node_list=list(g1.nodes())\n",
    "    max_weight_of_all=0\n",
    "    for a in node_list:\n",
    "        for b in node_list:\n",
    "            if a==b:\n",
    "                continue\n",
    "            link = []\n",
    "            link.append(a)\n",
    "            link.append(b)\n",
    "            edge_weight=g1.get_edge_data(a,b)['weight']\n",
    "            link.append(edge_weight)\n",
    "            linkset.append(link)\n",
    "            print('%d %d %d' % (a,b,edge_weight))\n",
    "            if edge_weight>max_weight_of_all:\n",
    "                max_weight_of_all=edge_weight\n",
    "\n",
    "    for link in linkset:\n",
    "        try:\n",
    "            linklist = links[str(link[0])]\n",
    "            linklist.append(link[1:])\n",
    "            links[str(link[0])] = linklist\n",
    "        except:\n",
    "            links[str(link[0])] = [link[1:]]\n",
    "\n",
    "    return links, max_weight_of_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(state):\n",
    "    #return hill_climbing(state)\n",
    "    return two_opt_swap(state)\n",
    "\n",
    "def hill_climbing(state):\n",
    "    node = randint(1, len(state)-1)\n",
    "    neighbors = []\n",
    "\n",
    "    for i in range(len(state)):\n",
    "        if i != node and i != 0:\n",
    "            tmp_state = state.copy()\n",
    "            tmp = tmp_state[i]\n",
    "            tmp_state[i] = tmp_state[node]\n",
    "            tmp_state[node] = tmp\n",
    "            neighbors.append(tmp_state)\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "def two_opt_swap(state):\n",
    "    global neighborhood_size\n",
    "    neighbors = []\n",
    "\n",
    "    for i in range(neighborhood_size):\n",
    "        node1 = 0\n",
    "        node2 = 0\n",
    "\n",
    "        while node1 == node2:\n",
    "            node1 = randint(1, len(state)-1)\n",
    "            node2 = randint(1, len(state)-1)\n",
    "\n",
    "        if node1 > node2:\n",
    "            swap = node1\n",
    "            node1 = node2\n",
    "            node2 = swap\n",
    "\n",
    "\n",
    "        tmp = state[node1:node2]\n",
    "        tmp_state = state[:node1] + tmp[::-1] +state[node2:]\n",
    "        neighbors.append(tmp_state)\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "def fitness(route, graph):\n",
    "    path_length = 0\n",
    "\n",
    "    for i in range(len(route)):\n",
    "        if(i+1 != len(route)):\n",
    "            dist = weight_distance(route[i], route[i+1], graph)\n",
    "            if dist != -1:\n",
    "                path_length = path_length + dist\n",
    "            else:\n",
    "                return max_fitness # there is no  such path\n",
    "\n",
    "        else:\n",
    "            dist = weight_distance(route[i], route[0], graph)\n",
    "            if dist != -1:\n",
    "                path_length = path_length + dist\n",
    "            else:\n",
    "                return max_fitness # there is no  such path\n",
    "\n",
    "    return path_length\n",
    "\n",
    "# not used in this code but some datasets has 2-or-more dimensional data points, in this case it is usable\n",
    "def euclidean_distance(city1, city2):\n",
    "    return math.sqrt((city1[0] - city2[0])**2 + ((city1[1] - city2[1])**2))\n",
    "\n",
    "def weight_distance(city1, city2, graph):\n",
    "    global max_fitness\n",
    "\n",
    "    neighbors = graph[str(city1)]\n",
    "\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor[0] == int(city2):\n",
    "            return neighbor[1]\n",
    "\n",
    "    return -1 #there can't be minus distance, so -1 means there is not any city found in graph or there is not such edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabu_search(nodes, probability, min_weight, max_weight):\n",
    "    global max_fitness, start_node\n",
    "    graph, max_weight = cook_data(nodes, probability, min_weight, max_weight)\n",
    "\n",
    "    ## Below, get the keys (node names) and shuffle them, and make start_node as start\n",
    "    s0 = list(graph.keys())\n",
    "    shuffle(s0)\n",
    "\n",
    "    if int(s0[0]) != start_node:\n",
    "        for i in range(len(s0)):\n",
    "            if  int(s0[i]) == start_node:\n",
    "                swap = s0[0]\n",
    "                s0[0] = s0[i]\n",
    "                s0[i] = swap\n",
    "                break;\n",
    "\n",
    "    # max_fitness will act like infinite fitness\n",
    "    max_fitness = ((max_weight) * (len(s0)))+1\n",
    "    sBest = s0\n",
    "    vBest = fitness(s0, graph)\n",
    "    bestCandidate = s0\n",
    "    tabuList = []\n",
    "    tabuList.append(s0)\n",
    "    stop = False\n",
    "    best_keep_turn = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    while not stop :\n",
    "        sNeighborhood = getNeighbors(bestCandidate)\n",
    "        bestCandidate = sNeighborhood[0]\n",
    "        for sCandidate in sNeighborhood:\n",
    "            if (sCandidate not in tabuList) and ((fitness(sCandidate, graph) < fitness(bestCandidate, graph))):\n",
    "                bestCandidate = sCandidate\n",
    "\n",
    "        if (fitness(bestCandidate, graph) < fitness(sBest, graph)):\n",
    "            sBest = bestCandidate\n",
    "            vBest = fitness(sBest, graph)\n",
    "            best_keep_turn = 0\n",
    "\n",
    "        tabuList.append(bestCandidate)\n",
    "        if (len(tabuList) > maxTabuSize):\n",
    "            tabuList.pop(0)\n",
    "\n",
    "        if best_keep_turn == stoppingTurn:\n",
    "            stop = True\n",
    "\n",
    "        best_keep_turn += 1\n",
    "\n",
    "    exec_time =  time.time() - start_time\n",
    "    return sBest, vBest, exec_time\n",
    "\n",
    "\n",
    "\n",
    "## Tabu Search Takes edge-list in a given format:\n",
    "#nodefrom nodeto weight\n",
    "#0 1 5\n",
    "#3 2 4\n",
    "#1 0 3\n",
    "#Undirectional edges should be written 2 times for both nodes.\n",
    "maxTabuSize = 10000\n",
    "neighborhood_size = 500\n",
    "stoppingTurn = 500\n",
    "max_fitness = 0\n",
    "start_node = 0\n",
    "solution, value, exec_time = tabu_search(nodes=100, probability=1, min_weight=10, max_weight=20)\n",
    "\n",
    "print(solution)\n",
    "print('----> '.join(a for a in solution))\n",
    "print('Shortest Distance : %d' %(value))\n",
    "print('Solved in %s seconds'%exec_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ozan Polatbilek, (Jul 9, 2019) *Tabu search on Travelling Salesman Problem* [online] Available at: <https://github.com/polatbilek/Tabu-search-on-Travelling-Salesman-Problem/blob/master/tabu_search.py> [Accessed on Apr 8, 2020]\n",
    "\n",
    "* C.-N. Fiechter, (July 16, 1992) *A parallel tabu search algorithm for large traveling salesman problems* [online] Available at: <https://core.ac.uk/download/pdf/82688573.pdf> [Accessed on Apr 12, 2020]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
